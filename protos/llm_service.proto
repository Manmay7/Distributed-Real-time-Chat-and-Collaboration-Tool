syntax = "proto3";

package llm;

service LLMService {
    rpc GetLLMAnswer(LLMRequest) returns (LLMResponse);
    rpc GetSmartReply(SmartReplyRequest) returns (SmartReplyResponse);
    rpc SummarizeConversation(SummarizeRequest) returns (SummarizeResponse);
    rpc GetContextSuggestions(ContextRequest) returns (SuggestionsResponse);
}

// Single consistent Message type used everywhere
message Message {
    string sender = 1;
    string content = 2;
}

message LLMRequest {
    string request_id = 1;
    string query = 2;
    repeated string context = 3;
    map<string, string> parameters = 4;
}

message LLMResponse {
    string request_id = 1;
    string answer = 2;
    float confidence = 3;
}

message SmartReplyRequest {
    string request_id = 1;
    repeated Message recent_messages = 2;  // Changed from ChatMessage to Message
    string user_id = 3;
}

message SmartReplyResponse {
    string request_id = 1;
    repeated string suggestions = 2;
}

message SummarizeRequest {
    string request_id = 1;
    repeated Message messages = 2;  // Changed from ChatMessage to Message
    int32 max_length = 3;
}

message SummarizeResponse {
    string request_id = 1;
    string summary = 2;
    repeated string key_points = 3;
}

message ContextRequest {
    string request_id = 1;
    repeated Message context = 2;
    string current_input = 3;
}

message SuggestionsResponse {
    string request_id = 1;
    repeated string suggestions = 2;
    repeated string topics = 3;
}